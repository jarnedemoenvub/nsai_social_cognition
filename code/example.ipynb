{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24fdf3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from json import dumps\n",
    "\n",
    "import torch\n",
    "\n",
    "from deepproblog.dataset import DataLoader\n",
    "from deepproblog.engines import ApproximateEngine, ExactEngine\n",
    "from deepproblog.evaluate import get_confusion_matrix\n",
    "from deepproblog.examples.MNIST.data import MNIST_train, MNIST_test, addition, datasets\n",
    "from deepproblog.examples.MNIST.network import MNIST_Net\n",
    "from deepproblog.model import Model\n",
    "from deepproblog.network import Network\n",
    "from deepproblog.train import train_model\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bfdc152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script dir:  c:\\Users\\jarne\\Documents\\Code Masterthesis\\nsai_social_cognition\\code\n"
     ]
    }
   ],
   "source": [
    "method = \"exact\"\n",
    "N = 1\n",
    "script_dir = os.getcwd()\n",
    "print(\"script dir: \", script_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1ac9e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = addition(N, \"train\")\n",
    "test_set = addition(N, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7773b493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'int'>\n",
      "<class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_set[0][0][0]))\n",
    "print(type(train_set[0][1][0]))\n",
    "print(type(train_set[0][2]))\n",
    "print(type(train_set[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "665c6c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label sum: 5\n"
     ]
    }
   ],
   "source": [
    "first_digit_tensor = train_set[0][0][0]\n",
    "second_digit_tensor = train_set[0][1][0]\n",
    "label_sum = train_set[0][2]\n",
    "\n",
    "# show the tensors as image\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(first_digit_tensor.squeeze(), cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(second_digit_tensor.squeeze(), cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Label sum:\", label_sum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8c06edf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchvision.datasets.mnist.MNIST"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(datasets[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0d08f7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0], [1]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f61b2986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing MNIST_train with tuple (the correct way):\n",
      "MNIST_train[(0,)] works!\n",
      "Type: <class 'torch.Tensor'>\n",
      "Shape: torch.Size([1, 28, 28])\n",
      "\n",
      "Testing MNIST_train[0] (direct integer - should fail):\n",
      "MNIST_train[0] failed: 'int' object is not subscriptable\n",
      "\n",
      "Testing MNIST_train with list:\n",
      "MNIST_train[[0]] works! Shape: torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# Let's test what gets passed to MNIST_train.__getitem__\n",
    "print(\"Testing MNIST_train with tuple (the correct way):\")\n",
    "try:\n",
    "    result1 = MNIST_train[(0,)]  # Tuple - this should work\n",
    "    print(\"MNIST_train[(0,)] works!\")\n",
    "    print(\"Type:\", type(result1))\n",
    "    print(\"Shape:\", result1.shape)\n",
    "except Exception as e:\n",
    "    print(\"MNIST_train[(0,)] failed:\", e)\n",
    "\n",
    "print(\"\\nTesting MNIST_train[0] (direct integer - should fail):\")\n",
    "try:\n",
    "    result2 = MNIST_train[0]  # Integer - this should fail\n",
    "    print(\"MNIST_train[0] works! Type:\", type(result2))\n",
    "except Exception as e:\n",
    "    print(\"MNIST_train[0] failed:\", e)\n",
    "\n",
    "print(\"\\nTesting MNIST_train with list:\")\n",
    "try:\n",
    "    result3 = MNIST_train[[0]]  # List\n",
    "    print(\"MNIST_train[[0]] works! Shape:\", result3.shape)\n",
    "except Exception as e:\n",
    "    print(\"MNIST_train[[0]] failed:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65242563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([tensor([[[-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9765, -0.8588,\n",
       "            -0.8588, -0.8588, -0.0118,  0.0667,  0.3725, -0.7961,  0.3020,\n",
       "             1.0000,  0.9373, -0.0039, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -0.7647, -0.7176, -0.2627,  0.2078,  0.3333,  0.9843,\n",
       "             0.9843,  0.9843,  0.9843,  0.9843,  0.7647,  0.3490,  0.9843,\n",
       "             0.8980,  0.5294, -0.4980, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -0.6157,  0.8667,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,\n",
       "             0.9843,  0.9843,  0.9843,  0.9686, -0.2706, -0.3569, -0.3569,\n",
       "            -0.5608, -0.6941, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -0.8588,  0.7176,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,\n",
       "             0.5529,  0.4275,  0.9373,  0.8902, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -0.3725,  0.2235, -0.1608,  0.9843,  0.9843,  0.6078,\n",
       "            -0.9137, -1.0000, -0.6627,  0.2078, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -0.8902, -0.9922,  0.2078,  0.9843, -0.2941,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000,  0.0902,  0.9843,  0.4902,\n",
       "            -0.9843, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -0.9137,  0.4902,  0.9843,\n",
       "            -0.4510, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.7255,  0.8902,\n",
       "             0.7647,  0.2549, -0.1529, -0.9922, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.3647,\n",
       "             0.8824,  0.9843,  0.9843, -0.0667, -0.8039, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -0.6471,  0.4588,  0.9843,  0.9843,  0.1765, -0.7882, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -0.8745, -0.2706,  0.9765,  0.9843,  0.4667, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000,  0.9529,  0.9843,  0.9529, -0.4980,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -0.6392,  0.0196,  0.4353,  0.9843,  0.9843,  0.6235, -0.9843,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.6941,  0.1608,\n",
       "             0.7961,  0.9843,  0.9843,  0.9843,  0.9608,  0.4275, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -0.8118, -0.1059,  0.7333,  0.9843,\n",
       "             0.9843,  0.9843,  0.9843,  0.5765, -0.3882, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -0.8196, -0.4824,  0.6706,  0.9843,  0.9843,  0.9843,\n",
       "             0.9843,  0.5529, -0.3647, -0.9843, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.8588,\n",
       "             0.3412,  0.7176,  0.9843,  0.9843,  0.9843,  0.9843,  0.5294,\n",
       "            -0.3725, -0.9294, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000, -1.0000, -0.5686,  0.3490,  0.7725,\n",
       "             0.9843,  0.9843,  0.9843,  0.9843,  0.9137,  0.0431, -0.9137,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000, -1.0000,  0.0667,  0.9843,  0.9843,\n",
       "             0.9843,  0.6627,  0.0588,  0.0353, -0.8745, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000]]])],\n",
       " [tensor([[[-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -0.6000,  0.2471,  0.9843,  0.2471, -0.6078, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -0.6235,  0.8667,  0.9765,  0.9765,  0.9765,  0.8588, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.5765,\n",
       "             0.7804,  0.9843,  0.9765,  0.8745,  0.8275,  0.9765, -0.5529,\n",
       "            -0.9529, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -0.9216, -0.5294,  0.7569,\n",
       "             0.9765,  0.9843,  0.9765,  0.5843, -0.3412,  0.9765,  0.9843,\n",
       "            -0.0431, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000,  0.2784,  0.9765,  0.9765,\n",
       "             0.9765,  0.9843,  0.9765,  0.9765, -0.2471,  0.4824,  0.9843,\n",
       "             0.3098, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -0.6000,  0.8667,  0.9843,  0.9843,\n",
       "             0.4902, -0.1059,  0.9843,  0.7882, -0.6314, -0.3804,  1.0000,\n",
       "             0.3176, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -0.6235,  0.8667,  0.9765,  0.9765,  0.4039,\n",
       "            -0.9059, -0.4118, -0.0510, -0.8353, -1.0000, -1.0000,  0.9843,\n",
       "             0.9059, -0.6078, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -0.7020,  0.2941,  0.9843,  0.8275,  0.6314, -0.3412,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.9843,\n",
       "             0.9765,  0.2941, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -0.9451,  0.3961,  0.9765,  0.8824, -0.4431, -0.8510, -0.7804,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.9843,\n",
       "             0.9765,  0.5294, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -0.5529,  0.9765,  0.9765, -0.5059, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.9843,\n",
       "             0.9765,  0.5294, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "             0.5529,  0.9843,  0.4902, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000,\n",
       "             0.9843,  0.5373, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.4039,\n",
       "             0.9294,  0.9765, -0.1216, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.9843,\n",
       "             0.9765,  0.1608, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.3333,\n",
       "             0.9765,  0.8039, -0.8039, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -0.9451,  0.0588,  0.9843,\n",
       "             0.4588, -0.9059, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.3333,\n",
       "             0.9765,  0.7490, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -0.9451,  0.0275,  0.9765,  0.7647,\n",
       "            -0.4431, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.3333,\n",
       "             0.9765,  0.1373, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -0.6235,  0.2941,  0.9765,  0.3569, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.3255,\n",
       "             0.9843,  0.7647, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -0.1059,  0.8667,  0.9843,  0.2706, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.3333,\n",
       "             0.9765,  0.9529,  0.1451, -0.6235, -0.7725, -0.3333,  0.3961,\n",
       "             0.7647,  0.9843,  0.7490,  0.3098, -0.5608, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.3333,\n",
       "             0.9765,  0.9765,  0.9765,  0.7961,  0.6863,  0.9765,  0.9765,\n",
       "             0.9765,  0.5373,  0.0196, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.7804,\n",
       "             0.5608,  0.9765,  0.9765,  0.9843,  0.9765,  0.9765,  0.8275,\n",
       "             0.1373, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -0.8039,  0.0039,  0.9765,  0.9843,  0.9765,  0.1059, -0.7098,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "            -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000]]])],\n",
       " 5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d4f75a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0], [1]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MNIST Indices\n",
    "train_set.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "353d907f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set._get_label(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b758dcb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0::addition(p0_0,p1_0,5), {p0_0: tensor(train(0)), p1_0: tensor(train(1))})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# High level\n",
    "import itertools\n",
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import Callable, List, Iterable, Tuple\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from problog.logic import Term, list2term, Constant\n",
    "from torch.utils.data import Dataset as TorchDataset\n",
    "\n",
    "from deepproblog.dataset import Dataset\n",
    "from deepproblog.query import Query\n",
    "\n",
    "_DATA_ROOT = script_dir\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]\n",
    ")\n",
    "\n",
    "datasets = {\n",
    "    \"train\": torchvision.datasets.MNIST(\n",
    "        root=str(_DATA_ROOT), train=True, download=True, transform=transform\n",
    "    ),\n",
    "    \"test\": torchvision.datasets.MNIST(\n",
    "        root=str(_DATA_ROOT), train=False, download=True, transform=transform\n",
    "    ),\n",
    "}\n",
    "\n",
    "def digits_to_number(digits: Iterable[int]) -> int:\n",
    "    number = 0\n",
    "    for d in digits:\n",
    "        number *= 10\n",
    "        number += d\n",
    "    return number\n",
    "\n",
    "class MNISTOperator(Dataset, TorchDataset):\n",
    "    def __getitem__(self, index: int) -> Tuple[list, list, int]:\n",
    "        # get the two images\n",
    "        l1, l2 = self.data[index]\n",
    "        # get their sum as label\n",
    "        label = self._get_label(index)\n",
    "        l1 = [self.dataset[x][0] for x in l1]\n",
    "        l2 = [self.dataset[x][0] for x in l2]\n",
    "        return l1, l2, label\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset_name: str,\n",
    "        function_name: str,\n",
    "        operator: Callable[[List[int]], int],\n",
    "        size=1,\n",
    "        arity=2,\n",
    "        seed=None,\n",
    "    ):\n",
    "        \"\"\"Generic dataset for operator(img, img) style datasets.\n",
    "\n",
    "        :param dataset_name: Dataset to use (train, val, test)\n",
    "        :param function_name: Name of Problog function to query.\n",
    "        :param operator: Operator to generate correct examples\n",
    "        :param size: Size of numbers (number of digits)\n",
    "        :param arity: Number of arguments for the operator\n",
    "        :param seed: Seed for RNG\n",
    "        \"\"\"\n",
    "        super(MNISTOperator, self).__init__()\n",
    "        assert size >= 1\n",
    "        assert arity >= 1\n",
    "        self.dataset_name = dataset_name\n",
    "        self.dataset = datasets[self.dataset_name]\n",
    "        self.function_name = function_name\n",
    "        self.operator = operator\n",
    "        self.size = size\n",
    "        self.arity = arity\n",
    "        self.seed = seed\n",
    "        mnist_indices = list(range(len(self.dataset)))\n",
    "        if seed is not None:\n",
    "            rng = random.Random(seed)\n",
    "            rng.shuffle(mnist_indices)\n",
    "        dataset_iter = iter(mnist_indices)\n",
    "        # Build list of examples (mnist indices)\n",
    "        self.data = []\n",
    "        try:\n",
    "            while dataset_iter:\n",
    "                self.data.append(\n",
    "                    [\n",
    "                        [next(dataset_iter) for _ in range(self.size)]\n",
    "                        for _ in range(self.arity)\n",
    "                    ]\n",
    "                )\n",
    "        except StopIteration:\n",
    "            pass\n",
    "\n",
    "    def to_file_repr(self, i):\n",
    "        \"\"\"Old file represenation dump. Not a very clear format as multi-digit arguments are not separated\"\"\"\n",
    "        return f\"{tuple(itertools.chain(*self.data[i]))}\\t{self._get_label(i)}\"\n",
    "\n",
    "    def to_json(self):\n",
    "        \"\"\"\n",
    "        Convert to JSON, for easy comparisons with other systems.\n",
    "\n",
    "        Format is [EXAMPLE, ...]\n",
    "        EXAMPLE :- [ARGS, expected_result]\n",
    "        ARGS :- [MULTI_DIGIT_NUMBER, ...]\n",
    "        MULTI_DIGIT_NUMBER :- [mnist_img_id, ...]\n",
    "        \"\"\"\n",
    "        data = [(self.data[i], self._get_label(i)) for i in range(len(self))]\n",
    "        return json.dumps(data)\n",
    "\n",
    "    def to_query(self, i: int) -> Query:\n",
    "        \"\"\"Generate queries\"\"\"\n",
    "        mnist_indices = self.data[i]\n",
    "        expected_result = self._get_label(i)\n",
    "\n",
    "        # Build substitution dictionary for the arguments\n",
    "        subs = dict()\n",
    "        var_names = []\n",
    "        for i in range(self.arity):\n",
    "            inner_vars = []\n",
    "            for j in range(self.size):\n",
    "                t = Term(f\"p{i}_{j}\")\n",
    "                subs[t] = Term(\n",
    "                    \"tensor\",\n",
    "                    Term(\n",
    "                        self.dataset_name,\n",
    "                        Constant(mnist_indices[i][j]),\n",
    "                    ),\n",
    "                )\n",
    "                inner_vars.append(t)\n",
    "            var_names.append(inner_vars)\n",
    "\n",
    "        # Build query\n",
    "        if self.size == 1:\n",
    "            return Query(\n",
    "                Term(\n",
    "                    self.function_name,\n",
    "                    *(e[0] for e in var_names),\n",
    "                    Constant(expected_result),\n",
    "                ),\n",
    "                subs,\n",
    "            )\n",
    "        else:\n",
    "            return Query(\n",
    "                Term(\n",
    "                    self.function_name,\n",
    "                    *(list2term(e) for e in var_names),\n",
    "                    Constant(expected_result),\n",
    "                ),\n",
    "                subs,\n",
    "            )\n",
    "\n",
    "    def _get_label(self, i: int):\n",
    "        mnist_indices = self.data[i]\n",
    "        # Figure out what the ground truth is, first map each parameter to the value:\n",
    "        ground_truth = [\n",
    "            digits_to_number(self.dataset[j][1] for j in i) for i in mnist_indices\n",
    "        ]\n",
    "        # Then compute the expected value:\n",
    "        expected_result = self.operator(ground_truth)\n",
    "        return expected_result\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "def addition(n: int, dataset: str, seed=None):\n",
    "    \"\"\"Returns a dataset for binary addition\"\"\"\n",
    "    return MNISTOperator(\n",
    "        dataset_name=dataset,\n",
    "        function_name=\"addition\" if n == 1 else \"multi_addition\",\n",
    "        operator=sum,\n",
    "        size=n,\n",
    "        arity=2,\n",
    "        seed=seed,\n",
    ")\n",
    "    \n",
    "train_setje = addition(N, \"train\")\n",
    "\n",
    "train_setje.to_query(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepproblog",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
