# Load scene priors from excel and change the nan values to None
scene_priors = {}
df_loaded = pd.read_excel(os.path.join(data_dir, "scene_priors.xlsx"))
for _, row in df_loaded.iterrows():
    scene_name = row['scene_category']
    valence = row['valence'] if not pd.isna(row['valence']) else None
    arousal = row['arousal'] if not pd.isna(row['arousal']) else None
    nr_samples = row['nr_samples'] if not pd.isna(row['nr_samples']) else 0
    scene_priors[scene_name] = (valence, arousal, nr_samples)




import numpy as np
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from tqdm import tqdm

def cluster_places_categories_weighted(scene_priors, n_clusters=10):
    valid_scenes = []
    features = []
    weights = []

    # Extract valid scenes
    for scene_name, (valence, arousal, nr_samples) in tqdm(scene_priors.items(), desc="Filtering scenes"):
        if valence is not None and arousal is not None:
            valid_scenes.append(scene_name)
            features.append([valence, arousal])
            weights.append(nr_samples)

    features = np.array(features)
    weights = np.array(weights)

    print(f"Valid scenes: {len(valid_scenes)}/{len(scene_priors)}")
    print(f"Total samples: {weights.sum()}")

    # Standardize the features
    scaler = StandardScaler()
    features_scaled = scaler.fit_transform(features)

    # True weighted KMeans
    kmeans = KMeans(
        n_clusters=n_clusters,
        random_state=42,
        n_init=10,
    )

    # Fit with sample_weight (this is TRUE weighted K-Means)
    kmeans.fit(features_scaled, sample_weight=weights)

    # Assign cluster labels directly
    labels = kmeans.labels_

    # Build dictionary mapping scene → cluster
    cluster_labels = {
        scene: int(cluster)
        for scene, cluster in zip(valid_scenes, labels)
    }

    # Convert centers back to original valence/arousal scale
    cluster_centers = scaler.inverse_transform(kmeans.cluster_centers_)

    return cluster_labels, cluster_centers, features, valid_scenes, weights

# Run clustering
cluster_labels, cluster_centers, scene_features, valid_scenes, scene_weights = cluster_places_categories_weighted(
    scene_priors, 
    n_clusters=nr_clusters)

# Print cluster statistics
print("\nCluster Statistics:")
for cluster_id in range(len(cluster_centers)):
    scenes_in_cluster = [s for s, c in cluster_labels.items() if c == cluster_id]
    total_samples = sum(scene_priors[s][2] for s in scenes_in_cluster)
    avg_valence = cluster_centers[cluster_id][0]
    avg_arousal = cluster_centers[cluster_id][1]
    print(f"Cluster {cluster_id}: {len(scenes_in_cluster)} scenes, {total_samples} samples")
    print(f"  Center: Valence={avg_valence:.2f}, Arousal={avg_arousal:.2f}")
    print()







# Visualize clusters
import matplotlib.pyplot as plt
import matplotlib as mpl
import matplotlib.patheffects
def visualize_clusters_2d(cluster_labels, cluster_centers, scene_features, valid_scenes, scene_weights, scene_priors):
    """2D visualization of clusters on valence-arousal plane with cluster ID labels on each point."""
    plt.figure(figsize=(14, 10))
    
    # Colors for each cluster
    colors = plt.cm.tab20(np.linspace(0, 1, len(cluster_centers)))
    
    for i, scene_name in enumerate(valid_scenes):
        cluster_id = cluster_labels[scene_name]
        valence, arousal = scene_features[i]
        size = np.log1p(scene_weights[i]) * 20
        
        # Scatter point
        plt.scatter(valence, arousal, 
                    c=[colors[cluster_id]], 
                    s=size, 
                    alpha=0.75, 
                    edgecolors='black', 
                    linewidth=0.5)
        
        # Add cluster ID text next to the point
        plt.text(valence, arousal, str(cluster_id),
                 fontsize=8, 
                 ha='center', va='center',
                 color='white',
                 path_effects=[
                     mpl.patheffects.Stroke(linewidth=1.5, foreground='black'),
                     mpl.patheffects.Normal()
                 ])
    
    # Plot cluster centers
    plt.scatter(cluster_centers[:, 0], cluster_centers[:, 1], 
                c='red', s=300, marker='X', edgecolors='black', linewidth=2, 
                label='Cluster Centers', zorder=5)
    
    # Annotate cluster centers
    for i, (v, a) in enumerate(cluster_centers):
        plt.annotate(f'C{i}', (v, a), fontsize=14, fontweight='bold', 
                     ha='left', va='center', color='white',
                     path_effects=[
                         mpl.patheffects.Stroke(linewidth=2, foreground='black'),
                         mpl.patheffects.Normal()
                     ])
    
    plt.xlabel('Valence', fontsize=14)
    plt.ylabel('Arousal', fontsize=14)
    plt.title('Places365 Categories Clustered by Valence-Arousal (weighted by samples)', fontsize=16)
    plt.grid(True, alpha=0.3)
    plt.legend()
    plt.tight_layout()
    plt.show()
    
    # Print all scenes per cluster
    print("\n" + "="*80)
    print("DETAILED CLUSTER BREAKDOWN")
    print("="*80)
    for cluster_id in range(len(cluster_centers)):
        scenes_in_cluster = sorted([s for s, c in cluster_labels.items() if c == cluster_id])
        total_samples = sum(scene_priors[s][2] for s in scenes_in_cluster)
        avg_valence = cluster_centers[cluster_id][0]
        avg_arousal = cluster_centers[cluster_id][1]
        
        print(f"\n{'='*80}")
        print(f"CLUSTER {cluster_id}")
        print(f"{'='*80}")
        print(f"Center: Valence={avg_valence:.2f}, Arousal={avg_arousal:.2f}")
        print(f"Number of scenes: {len(scenes_in_cluster)}")
        print(f"Total samples: {total_samples}")
        print(f"\nAll scenes in this cluster:")
        print("-" * 80)
        
        for scene_name in scenes_in_cluster:
            v, a, n = scene_priors[scene_name]
            print(f"  • {scene_name:30s} | V={v:.2f}, A={a:.2f}, N={n:4d}")
        print()

visualize_clusters_2d(cluster_labels, cluster_centers, scene_features, valid_scenes, scene_weights, scene_priors)








# Now create a scatterplots of the cluster centers together with the valence arousal points of the emotions
def plot_clusters_with_emotions(cluster_centers):
    plt.figure(figsize=(12, 10))
    
    # Plot cluster centers
    plt.scatter(cluster_centers[:, 0], cluster_centers[:, 1], 
                c='red', s=300, marker='X', edgecolors='black', linewidth=2, 
                label='Cluster Centers', zorder=5)
    
    # Annotate cluster centers
    for i, (v, a) in enumerate(cluster_centers):
        plt.annotate(f'C{i}', (v, a), fontsize=14, fontweight='bold', 
                     ha='left', va='center', color='white',
                     path_effects=[
                         mpl.patheffects.Stroke(linewidth=2, foreground='black'),
                         mpl.patheffects.Normal()
                     ])
    
    # Plot emotion points
    for emo in df['emotion'].unique():
        subset = df[df['emotion'] == emo.lower()]
        avg_valence = subset['valence'].mean() + 3
        avg_arousal = subset['arousal'].mean()
        plt.scatter(avg_valence, avg_arousal, label=emo, s=150, alpha=0.7)
        plt.text(avg_valence, avg_arousal, emo,
                 fontsize=10, fontweight='bold',
                 ha='center', va='center',
                 color='black',
                 path_effects=[
                     mpl.patheffects.Stroke(linewidth=1.5, foreground='white'),
                     mpl.patheffects.Normal()
                 ])
    
    plt.xlabel('Valence', fontsize=14)
    plt.ylabel('Arousal', fontsize=14)
    plt.title('Places365 Cluster Centers with Emotion Averages', fontsize=16)
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.show()

plot_clusters_with_emotions(cluster_centers)







# cluster_names = ["industrial_stress",
#                  "busy_social",
#                  "functional_work",
#                  "active_recreation",
#                  "community",
#                  "indoor",
#                  "institutional_public",
#                  "crowded_urban",
#                  "leisure"]

# # Find categories not in cluster_labels (those without valence/arousal data)
# unassigned_categories = [cat for cat in scene_categories if cat not in cluster_labels]

# # Randomly assign them to clusters
# random.seed(42)  # For reproducibility
# for cat in unassigned_categories:
#     random_cluster = random.randint(0, len(cluster_centers) - 1)
#     cluster_labels[cat] = random_cluster

# # Verify all categories are now assigned
# assert len(cluster_labels) == len(scene_categories), "Not all categories are assigned!"

# # Update the cluster_dict with all categories
# cluster_dict = {}
# for cluster_id in range(len(cluster_centers)):
#     scenes_in_cluster = sorted([s for s, c in cluster_labels.items() if c == cluster_id])
#     cluster_dict[cluster_names[cluster_id]] = scenes_in_cluster
#     print(f"Cluster {cluster_id} ({cluster_names[cluster_id]}): {len(scenes_in_cluster)} scenes")

# # Convert to DataFrame and save
# max_len = max(len(scenes) for scenes in cluster_dict.values())
# for key in cluster_dict:
#     scenes = cluster_dict[key]
#     cluster_dict[key] = scenes + [""] * (max_len - len(scenes))

# df_clusters = pd.DataFrame(cluster_dict)

# # Save to Excel file
# output_path = os.path.join(data_dir, f"scene_clusters_{nr_clusters}.xlsx")
# df_clusters.to_excel(output_path, index=False)

# print(f"\nscene_clusters_{nr_clusters}.xlsx saved to: {output_path}")