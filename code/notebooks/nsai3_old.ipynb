{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "628180fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
    "import torch\n",
    "import os\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "from deepproblog.dataset import Dataset, DataLoader\n",
    "from torch.utils.data import Dataset as TorchDataset\n",
    "from problog.logic import Term, Constant, Var\n",
    "\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mtcnn import MTCNN\n",
    "import random\n",
    "from deepproblog.utils.stop_condition import EpochStop\n",
    "from deepproblog.optimizer import SGD\n",
    "\n",
    "from deepproblog.model import Model\n",
    "from deepproblog.network import Network\n",
    "from deepproblog.engines import ExactEngine\n",
    "from deepproblog.query import Query\n",
    "from deepproblog.train import train_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "5ba3b599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBAL VARS\n",
    "training_size_perc = 1\n",
    "epochs = 2\n",
    "lr_scene_reduction = 0.0001\n",
    "lr_faces = 0.0001\n",
    "lr_scenes = 0.0001\n",
    "lr_model = 0.0001\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "be571aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script_dir: c:\\Users\\jarne\\Documents\\Code Masterthesis\\nsai_social_cognition\\code\\notebooks\n",
      "base_dir: c:\\Users\\jarne\\Documents\\Code Masterthesis\\nsai_social_cognition\n",
      "data_dir: c:\\Users\\jarne\\Documents\\Code Masterthesis\\nsai_social_cognition\\data\n",
      "findingemo_dir: c:\\Users\\jarne\\Documents\\Code Masterthesis\\nsai_social_cognition\\data\\FindingEmo_Images\n",
      "prolog_dir: c:\\Users\\jarne\\Documents\\Code Masterthesis\\nsai_social_cognition\\code\\prolog\n"
     ]
    }
   ],
   "source": [
    "# Directories\n",
    "script_dir = os.getcwd()\n",
    "print(\"script_dir:\", script_dir)\n",
    "base_dir = os.path.dirname(os.path.dirname(script_dir))\n",
    "print(\"base_dir:\", base_dir)\n",
    "data_dir = os.path.join(base_dir, \"data\")\n",
    "print(\"data_dir:\", data_dir)\n",
    "findingemo_dir = os.path.join(data_dir, \"FindingEmo_Images\")\n",
    "print(\"findingemo_dir:\", findingemo_dir)\n",
    "prolog_dir = os.path.join(base_dir, \"code\", \"prolog\")\n",
    "print(\"prolog_dir:\", prolog_dir)\n",
    "df = pd.read_pickle(os.path.join(data_dir, \"dataframe_cleaned.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "895c7dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_categories_hf = ['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral']\n",
    "\n",
    "EMOTION_SETS = [[\"Serenity\", \"Joy\", \"Ecstasy\"],\n",
    "                    [\"Acceptance\", \"Trust\", \"Admiration\"],\n",
    "                    [\"Apprehension\", \"Fear\", \"Terror\"],\n",
    "                    [\"Distraction\", \"Surprise\", \"Amazement\"],\n",
    "                    [\"Pensiveness\", \"Sadness\", \"Grief\"],\n",
    "                    [\"Boredom\", \"Disgust\", \"Loathing\"],\n",
    "                    [\"Annoyance\", \"Anger\", \"Rage\"],\n",
    "                    [\"Interest\", \"Anticipation\", \"Vigilance\"]]\n",
    "\n",
    "EMO8_LIST = [l[1] for l in EMOTION_SETS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "9b9bfec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the mapping to 8 emotions as defined in the FindingEmo code\n",
    "EMO8_MAPPING = {}\n",
    "\n",
    "for i, leaf in enumerate(EMOTION_SETS):\n",
    "    for emo in leaf:\n",
    "        EMO8_MAPPING[emo] = EMO8_LIST[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d959ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the different emo8's  \n",
    "basic_6_emotions = [\"Anger\", \"Disgust\", \"Fear\", \"Joy\", \"Sadness\", \"Surprise\"]\n",
    "basic_6_emotions_idx = {emo: i for i, emo in enumerate(basic_6_emotions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23849218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Anger': 0, 'Disgust': 1, 'Fear': 2, 'Joy': 3, 'Sadness': 4, 'Surprise': 5}"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_6_emotions_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bbfb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load category names\n",
    "scene_categories_path = os.path.join(data_dir, \"places365/categories_places365.txt\")\n",
    "with open(scene_categories_path) as f:\n",
    "    scene_categories = [line.strip().split(' ')[0][3:] for line in f]\n",
    "    # If there is a / in the category name, replace it with _\n",
    "    scene_categories = [cat.replace('/', '_') for cat in scene_categories]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d93671",
   "metadata": {},
   "outputs": [],
   "source": [
    "places365_to_13categories = {\n",
    "    # --- Transport infrastructure ---\n",
    "    \"airfield\": \"transport_infrastructure\",\n",
    "    \"airplane_cabin\": \"transport_infrastructure\",\n",
    "    \"airport_terminal\": \"transport_infrastructure\",\n",
    "    \"railroad_track\": \"transport_infrastructure\",\n",
    "    \"train_interior\": \"transport_infrastructure\",\n",
    "    \"train_station_platform\": \"transport_infrastructure\",\n",
    "    \"subway_station_platform\": \"transport_infrastructure\",\n",
    "    \"bridge\": \"transport_infrastructure\",\n",
    "    \"runway\": \"transport_infrastructure\",\n",
    "    \"highway\": \"transport_infrastructure\",\n",
    "    \"garage_indoor\": \"transport_infrastructure\",\n",
    "    \"garage_outdoor\": \"transport_infrastructure\",\n",
    "    \"bus_interior\": \"transport_infrastructure\",\n",
    "    \"bus_station_indoor\": \"transport_infrastructure\",\n",
    "    \"harbor\": \"transport_infrastructure\",\n",
    "    \"viaduct\": \"transport_infrastructure\",\n",
    "    \"heliport\": \"transport_infrastructure\",\n",
    "    \"parking_garage_indoor\": \"transport_infrastructure\",\n",
    "    \"parking_garage_outdoor\": \"transport_infrastructure\",\n",
    "    \"car_interior\": \"transport_infrastructure\",\n",
    "    \"cockpit\": \"transport_infrastructure\",\n",
    "    \"berth\": \"transport_infrastructure\",\n",
    "\n",
    "    # --- Indoor residential ---\n",
    "    \"bedroom\": \"indoor_residential\",\n",
    "    \"bathroom\": \"indoor_residential\",\n",
    "    \"living_room\": \"indoor_residential\",\n",
    "    \"kitchen\": \"indoor_residential\",\n",
    "    \"attic\": \"indoor_residential\",\n",
    "    \"childs_room\": \"indoor_residential\",\n",
    "    \"closet\": \"indoor_residential\",\n",
    "    \"dining_room\": \"indoor_residential\",\n",
    "    \"dorm_room\": \"indoor_residential\",\n",
    "    \"hotel_room\": \"indoor_residential\",\n",
    "    \"mansion\": \"indoor_residential\",\n",
    "    \"nursery\": \"indoor_residential\",\n",
    "    \"television_room\": \"indoor_residential\",\n",
    "    \"pantry\": \"indoor_residential\",\n",
    "    \"playroom\": \"indoor_residential\",\n",
    "    \"house\": \"indoor_residential\",\n",
    "    \"apartment_building_outdoor\": \"indoor_residential\",\n",
    "    \"balcony_interior\": \"indoor_residential\",\n",
    "    \"banquet_hall\": \"indoor_residential\",\n",
    "    \"porch\": \"indoor_residential\",\n",
    "    \"jacuzzi_indoor\": \"indoor_residential\",\n",
    "    \"shower\": \"indoor_residential\",\n",
    "    \"alcove\": \"indoor_residential\",\n",
    "    \"bedchamber\": \"indoor_residential\",\n",
    "    \"ballroom\": \"indoor_residential\",\n",
    "    \"basement\": \"indoor_residential\",\n",
    "    \"dressing_room\": \"indoor_residential\",\n",
    "    \"home_office\": \"indoor_residential\",\n",
    "    \"home_theater\": \"indoor_residential\",\n",
    "    \"manufactured_home\": \"indoor_residential\",\n",
    "    \"utility_room\": \"indoor_residential\",\n",
    "    \"wet_bar\": \"indoor_residential\",\n",
    "    \"youth_hostel\": \"indoor_residential\",\n",
    "\n",
    "    # --- Indoor commercial ---\n",
    "    \"bakery_shop\": \"indoor_commercial\",\n",
    "    \"bar\": \"indoor_commercial\",\n",
    "    \"bookstore\": \"indoor_commercial\",\n",
    "    \"butchers_shop\": \"indoor_commercial\",\n",
    "    \"candy_store\": \"indoor_commercial\",\n",
    "    \"clothing_store\": \"indoor_commercial\",\n",
    "    \"department_store\": \"indoor_commercial\",\n",
    "    \"fastfood_restaurant\": \"indoor_commercial\",\n",
    "    \"florist_shop_indoor\": \"indoor_commercial\",\n",
    "    \"gift_shop\": \"indoor_commercial\",\n",
    "    \"jewelry_shop\": \"indoor_commercial\",\n",
    "    \"market_indoor\": \"indoor_commercial\",\n",
    "    \"pet_shop\": \"indoor_commercial\",\n",
    "    \"pharmacy\": \"indoor_commercial\",\n",
    "    \"shoe_shop\": \"indoor_commercial\",\n",
    "    \"shopping_mall_indoor\": \"indoor_commercial\",\n",
    "    \"supermarket\": \"indoor_commercial\",\n",
    "    \"toyshop\": \"indoor_commercial\",\n",
    "    \"restaurant\": \"indoor_commercial\",\n",
    "    \"restaurant_kitchen\": \"indoor_commercial\",\n",
    "    \"restaurant_patio\": \"indoor_commercial\",\n",
    "    \"pizzeria\": \"indoor_commercial\",\n",
    "    \"pub_indoor\": \"indoor_commercial\",\n",
    "    \"sushi_bar\": \"indoor_commercial\",\n",
    "    \"hotel_outdoor\": \"indoor_commercial\",\n",
    "    \"amusement_arcade\": \"indoor_commercial\",\n",
    "    \"auto_showroom\": \"indoor_commercial\",\n",
    "    \"bakery_shop\": \"indoor_commercial\",\n",
    "    \"bank_vault\": \"indoor_commercial\",\n",
    "    \"bazaar_indoor\": \"indoor_commercial\",\n",
    "    \"beauty_salon\": \"indoor_commercial\",\n",
    "    \"cafeteria\": \"indoor_commercial\",\n",
    "    \"coffee_shop\": \"indoor_commercial\",\n",
    "    \"delicatessen\": \"indoor_commercial\",\n",
    "    \"discotheque\": \"indoor_commercial\",\n",
    "    \"drugstore\": \"indoor_commercial\",\n",
    "    \"fabric_store\": \"indoor_commercial\",\n",
    "    \"flea_market_indoor\": \"indoor_commercial\",\n",
    "    \"food_court\": \"indoor_commercial\",\n",
    "    \"hardware_store\": \"indoor_commercial\",\n",
    "    \"laundromat\": \"indoor_commercial\",\n",
    "    \"market_outdoor\": \"indoor_commercial\",\n",
    "    \"motel\": \"indoor_commercial\",\n",
    "    \"pub_indoor\": \"indoor_commercial\",\n",
    "    \"sauna\": \"indoor_commercial\",\n",
    "    \"server_room\": \"indoor_commercial\",\n",
    "    \"shoe_shop\": \"indoor_commercial\",\n",
    "    \"shopping_mall_indoor\": \"indoor_commercial\",\n",
    "    \"supermarket\": \"indoor_commercial\",\n",
    "    \"booth_indoor\": \"indoor_commercial\",\n",
    "    \"ice_cream_parlor\": \"indoor_commercial\",\n",
    "    \"general_store_indoor\": \"indoor_commercial\",\n",
    "    \"general_store_outdoor\": \"indoor_commercial\",\n",
    "    \"pavilion\": \"indoor_commercial\",\n",
    "    \"ticket_booth\": \"indoor_commercial\",\n",
    "\n",
    "    # --- Indoor institutional ---\n",
    "    \"art_gallery\": \"indoor_institutional\",\n",
    "    \"auditorium\": \"indoor_institutional\",\n",
    "    \"church_indoor\": \"indoor_institutional\",\n",
    "    \"classroom\": \"indoor_institutional\",\n",
    "    \"conference_room\": \"indoor_institutional\",\n",
    "    \"hospital\": \"indoor_institutional\",\n",
    "    \"hospital_room\": \"indoor_institutional\",\n",
    "    \"library_indoor\": \"indoor_institutional\",\n",
    "    \"lecture_room\": \"indoor_institutional\",\n",
    "    \"office\": \"indoor_institutional\",\n",
    "    \"office_cubicles\": \"indoor_institutional\",\n",
    "    \"schoolhouse\": \"indoor_institutional\",\n",
    "    \"science_museum\": \"indoor_institutional\",\n",
    "    \"nursing_home\": \"indoor_institutional\",\n",
    "    \"reception\": \"indoor_institutional\",\n",
    "    \"waiting_room\": \"indoor_institutional\",\n",
    "    \"museum_indoor\": \"indoor_institutional\",\n",
    "    \"biology_laboratory\": \"indoor_institutional\",\n",
    "    \"chemistry_lab\": \"indoor_institutional\",\n",
    "    \"clean_room\": \"indoor_institutional\",\n",
    "    \"conference_center\": \"indoor_institutional\",\n",
    "    \"courthouse\": \"indoor_institutional\",\n",
    "    \"embassy\": \"indoor_institutional\",\n",
    "    \"entrance_hall\": \"indoor_institutional\",\n",
    "    \"elevator_lobby\": \"indoor_institutional\",\n",
    "    \"elevator_shaft\": \"indoor_institutional\",\n",
    "    \"elevator_door\": \"indoor_institutional\",\n",
    "    \"escalator_indoor\": \"indoor_institutional\",\n",
    "    \"hospital\": \"indoor_institutional\",\n",
    "    \"kindergarden_classroom\": \"indoor_institutional\",\n",
    "    \"legislative_chamber\": \"indoor_institutional\",\n",
    "    \"library_outdoor\": \"indoor_institutional\",\n",
    "    \"lobby\": \"indoor_institutional\",\n",
    "    \"locker_room\": \"indoor_institutional\",\n",
    "    \"operating_room\": \"indoor_institutional\",\n",
    "    \"physics_laboratory\": \"indoor_institutional\",\n",
    "    \"recreation_room\": \"indoor_institutional\",\n",
    "    \"veterinarians_office\": \"indoor_institutional\",\n",
    "    \"atrium_public\": \"indoor_institutional\",\n",
    "    \"corridor\": \"indoor_institutional\",\n",
    "    \"computer_room\": \"indoor_institutional\",\n",
    "    \"mezzanine\": \"indoor_institutional\",\n",
    "    \"office_building\": \"indoor_institutional\",\n",
    "    \"jail_cell\": \"indoor_institutional\",\n",
    "    \"storage_room\": \"indoor_institutional\",\n",
    "\n",
    "    # --- Industrial facilities ---\n",
    "    \"assembly_line\": \"industrial_facility\",\n",
    "    \"auto_factory\": \"industrial_facility\",\n",
    "    \"engine_room\": \"industrial_facility\",\n",
    "    \"industrial_area\": \"industrial_facility\",\n",
    "    \"oilrig\": \"industrial_facility\",\n",
    "    \"construction_site\": \"industrial_facility\",\n",
    "    \"army_base\": \"industrial_facility\",\n",
    "    \"junkyard\": \"industrial_facility\",\n",
    "    \"repair_shop\": \"industrial_facility\",\n",
    "    \"loading_dock\": \"industrial_facility\",\n",
    "    \"fire_station\": \"industrial_facility\",\n",
    "    \"landing_deck\": \"industrial_facility\",\n",
    "    \"construction_site\": \"industrial_facility\",\n",
    "    \"gas_station\": \"industrial_facility\",\n",
    "    \"hangar_indoor\": \"industrial_facility\",\n",
    "    \"hangar_outdoor\": \"industrial_facility\",\n",
    "    \"dam\": \"industrial_facility\",\n",
    "    \"excavation\": \"industrial_facility\",\n",
    "    \"fire_escape\": \"industrial_facility\",\n",
    "    \"landfill\": \"industrial_facility\",\n",
    "    \"lock_chamber\": \"industrial_facility\",\n",
    "    \"trench\": \"industrial_facility\",\n",
    "    \"shed\": \"industrial_facility\",\n",
    "\n",
    "    # --- Urban outdoor ---\n",
    "    \"alley\": \"urban_outdoor\",\n",
    "    \"building_facade\": \"urban_outdoor\",\n",
    "    \"courtyard\": \"urban_outdoor\",\n",
    "    \"crosswalk\": \"urban_outdoor\",\n",
    "    \"downtown\": \"urban_outdoor\",\n",
    "    \"plaza\": \"urban_outdoor\",\n",
    "    \"street\": \"urban_outdoor\",\n",
    "    \"shopfront\": \"urban_outdoor\",\n",
    "    \"parking_lot\": \"urban_outdoor\",\n",
    "    \"residential_neighborhood\": \"urban_outdoor\",\n",
    "    \"skyscraper\": \"urban_outdoor\",\n",
    "    \"amusement_park\": \"urban_outdoor\",\n",
    "    \"arcade\": \"urban_outdoor\",\n",
    "    \"balcony_exterior\": \"urban_outdoor\",\n",
    "    \"bazaar_outdoor\": \"urban_outdoor\",\n",
    "    \"boardwalk\": \"urban_outdoor\",\n",
    "    \"driveway\": \"urban_outdoor\",\n",
    "    \"doorway_outdoor\": \"urban_outdoor\",\n",
    "    \"gazebo_exterior\": \"urban_outdoor\",\n",
    "    \"market_outdoor\": \"urban_outdoor\",\n",
    "    \"patio\": \"urban_outdoor\",\n",
    "    \"plaza\": \"urban_outdoor\",\n",
    "    \"promenade\": \"urban_outdoor\",\n",
    "    \"rope_bridge\": \"urban_outdoor\",\n",
    "    \"street\": \"urban_outdoor\",\n",
    "    \"tower\": \"urban_outdoor\",\n",
    "    \"slum\": \"urban_outdoor\",\n",
    "    \"sky\": \"urban_outdoor\",\n",
    "    \"roof_garden\": \"urban_outdoor\",\n",
    "    \"phone_booth\": \"urban_outdoor\",\n",
    "\n",
    "    # --- Natural landscapes ---\n",
    "    \"badlands\": \"natural_landscape\",\n",
    "    \"canyon\": \"natural_landscape\",\n",
    "    \"cliff\": \"natural_landscape\",\n",
    "    \"desert_sand\": \"natural_landscape\",\n",
    "    \"desert_vegetation\": \"natural_landscape\",\n",
    "    \"forest_broadleaf\": \"natural_landscape\",\n",
    "    \"forest_path\": \"natural_landscape\",\n",
    "    \"mountain\": \"natural_landscape\",\n",
    "    \"mountain_path\": \"natural_landscape\",\n",
    "    \"mountain_snowy\": \"natural_landscape\",\n",
    "    \"valley\": \"natural_landscape\",\n",
    "    \"volcano\": \"natural_landscape\",\n",
    "    \"rock_arch\": \"natural_landscape\",\n",
    "    \"rainforest\": \"natural_landscape\",\n",
    "    \"bamboo_forest\": \"natural_landscape\",\n",
    "    \"butte\": \"natural_landscape\",\n",
    "    \"canal_natural\": \"natural_landscape\",\n",
    "    \"cliff\": \"natural_landscape\",\n",
    "    \"coast\": \"natural_landscape\",\n",
    "    \"creek\": \"natural_landscape\",\n",
    "    \"crevasse\": \"natural_landscape\",\n",
    "    \"desert_road\": \"natural_landscape\",\n",
    "    \"field_road\": \"natural_landscape\",\n",
    "    \"forest_road\": \"natural_landscape\",\n",
    "    \"grotto\": \"natural_landscape\",\n",
    "    \"islet\": \"natural_landscape\",\n",
    "    \"lawn\": \"natural_landscape\",\n",
    "    \"marsh\": \"natural_landscape\",\n",
    "    \"swamp\": \"natural_landscape\",\n",
    "    \"vegetable_garden\": \"natural_landscape\",\n",
    "    \"wheat_field\": \"natural_landscape\",\n",
    "    \"wind_farm\": \"natural_landscape\",\n",
    "    \"windmill\": \"natural_landscape\",\n",
    "    \"zen_garden\": \"natural_landscape\",\n",
    "    \"canal_urban\": \"natural_landscape\",\n",
    "    \"fountain\": \"natural_landscape\",\n",
    "\n",
    "    # --- Cold environments ---\n",
    "    \"ice_floe\": \"cold_environment\",\n",
    "    \"ice_shelf\": \"cold_environment\",\n",
    "    \"iceberg\": \"cold_environment\",\n",
    "    \"igloo\": \"cold_environment\",\n",
    "    \"ski_resort\": \"cold_environment\",\n",
    "    \"ski_slope\": \"cold_environment\",\n",
    "    \"snowfield\": \"cold_environment\",\n",
    "    \"tundra\": \"cold_environment\",\n",
    "    \"glacier\": \"cold_environment\",\n",
    "\n",
    "    # --- Aquatic environments ---\n",
    "    \"aquarium\": \"aquatic_environment\",\n",
    "    \"beach\": \"aquatic_environment\",\n",
    "    \"boat_deck\": \"aquatic_environment\",\n",
    "    \"boathouse\": \"aquatic_environment\",\n",
    "    \"harbor\": \"aquatic_environment\",\n",
    "    \"lake_natural\": \"aquatic_environment\",\n",
    "    \"lagoon\": \"aquatic_environment\",\n",
    "    \"ocean\": \"aquatic_environment\",\n",
    "    \"pond\": \"aquatic_environment\",\n",
    "    \"river\": \"aquatic_environment\",\n",
    "    \"waterfall\": \"aquatic_environment\",\n",
    "    \"swimming_pool_indoor\": \"aquatic_environment\",\n",
    "    \"swimming_pool_outdoor\": \"aquatic_environment\",\n",
    "    \"swimming_hole\": \"aquatic_environment\",\n",
    "    \"hot_spring\": \"aquatic_environment\",\n",
    "    \"beach_house\": \"aquatic_environment\",\n",
    "    \"fishpond\": \"aquatic_environment\",\n",
    "    \"moat_water\": \"aquatic_environment\",\n",
    "    \"pier\": \"aquatic_environment\",\n",
    "    \"raft\": \"aquatic_environment\",\n",
    "    \"watering_hole\": \"aquatic_environment\",\n",
    "    \"wave\": \"aquatic_environment\",\n",
    "    \"water_tower\": \"aquatic_environment\",\n",
    "    \"underwater_ocean_deep\": \"aquatic_environment\",\n",
    "    \"lighthouse\": \"aquatic_environment\",\n",
    "\n",
    "\n",
    "    # --- Religious or historical sites ---\n",
    "    \"church_outdoor\": \"religious_or_historical_site\",\n",
    "    \"mosque_outdoor\": \"religious_or_historical_site\",\n",
    "    \"synagogue_outdoor\": \"religious_or_historical_site\",\n",
    "    \"temple_asia\": \"religious_or_historical_site\",\n",
    "    \"catacomb\": \"religious_or_historical_site\",\n",
    "    \"mausoleum\": \"religious_or_historical_site\",\n",
    "    \"palace\": \"religious_or_historical_site\",\n",
    "    \"castle\": \"religious_or_historical_site\",\n",
    "    \"ruin\": \"religious_or_historical_site\",\n",
    "    \"arch\": \"religious_or_historical_site\",\n",
    "    \"amphitheater\": \"religious_or_historical_site\",\n",
    "    \"archaelogical_excavation\": \"religious_or_historical_site\",\n",
    "    \"burial_chamber\": \"religious_or_historical_site\",\n",
    "    \"cemetery\": \"religious_or_historical_site\",\n",
    "    \"chalet\": \"religious_or_historical_site\",\n",
    "    \"kasbah\": \"religious_or_historical_site\",\n",
    "    \"medina\": \"religious_or_historical_site\",\n",
    "    \"pagoda\": \"religious_or_historical_site\",\n",
    "    \"throne_room\": \"religious_or_historical_site\",\n",
    "\n",
    "    # --- Sports and entertainment ---\n",
    "    \"arena_hockey\": \"sports_and_entertainment\",\n",
    "    \"arena_performance\": \"sports_and_entertainment\",\n",
    "    \"arena_rodeo\": \"sports_and_entertainment\",\n",
    "    \"baseball_field\": \"sports_and_entertainment\",\n",
    "    \"basketball_court_indoor\": \"sports_and_entertainment\",\n",
    "    \"boxing_ring\": \"sports_and_entertainment\",\n",
    "    \"football_field\": \"sports_and_entertainment\",\n",
    "    \"gymnasium_indoor\": \"sports_and_entertainment\",\n",
    "    \"martial_arts_gym\": \"sports_and_entertainment\",\n",
    "    \"racecourse\": \"sports_and_entertainment\",\n",
    "    \"stadium_football\": \"sports_and_entertainment\",\n",
    "    \"stadium_soccer\": \"sports_and_entertainment\",\n",
    "    \"stage_indoor\": \"sports_and_entertainment\",\n",
    "    \"stage_outdoor\": \"sports_and_entertainment\",\n",
    "    \"bowling_alley\": \"sports_and_entertainment\",\n",
    "    \"movie_theater_indoor\": \"sports_and_entertainment\",\n",
    "    \"amphitheater\": \"sports_and_entertainment\",\n",
    "    \"athletic_field_outdoor\": \"sports_and_entertainment\",\n",
    "    \"ball_pit\": \"sports_and_entertainment\",\n",
    "    \"baseball_field\": \"sports_and_entertainment\",\n",
    "    \"basketball_court_indoor\": \"sports_and_entertainment\",\n",
    "    \"bow_window_indoor\": \"sports_and_entertainment\",\n",
    "    \"boxing_ring\": \"sports_and_entertainment\",\n",
    "    \"bullring\": \"sports_and_entertainment\",\n",
    "    \"football_field\": \"sports_and_entertainment\",\n",
    "    \"raceway\": \"sports_and_entertainment\",\n",
    "    \"soccer_field\": \"sports_and_entertainment\",\n",
    "    \"stadium_baseball\": \"sports_and_entertainment\",\n",
    "    \"staircase\": \"sports_and_entertainment\",\n",
    "    \"topiary_garden\": \"sports_and_entertainment\",\n",
    "    \"water_park\": \"sports_and_entertainment\",\n",
    "    \"carrousel\": \"sports_and_entertainment\",\n",
    "    \"dining_hall\": \"sports_and_entertainment\",\n",
    "    \"diner_outdoor\": \"sports_and_entertainment\",\n",
    "    \"ice_skating_rink_indoor\": \"sports_and_entertainment\",\n",
    "    \"ice_skating_rink_outdoor\": \"sports_and_entertainment\",\n",
    "\n",
    "\n",
    "    # --- Cultural spaces ---\n",
    "    \"art_studio\": \"cultural_space\",\n",
    "    \"art_school\": \"cultural_space\",\n",
    "    \"music_studio\": \"cultural_space\",\n",
    "    \"television_studio\": \"cultural_space\",\n",
    "    \"museum_outdoor\": \"cultural_space\",\n",
    "    \"artists_loft\": \"cultural_space\",\n",
    "    \"archive\": \"cultural_space\",\n",
    "    \"galley\": \"cultural_space\",\n",
    "    \"japanese_garden\": \"cultural_space\",\n",
    "    \"natural_history_museum\": \"cultural_space\",\n",
    "    \"music_studio\": \"cultural_space\",\n",
    "    \"orchestra_pit\": \"cultural_space\",\n",
    "\n",
    "    # --- Rural or recreational area ---\n",
    "    \"aqueduct\": \"rural_or_recreational_area\",\n",
    "    \"barn\": \"rural_or_recreational_area\",\n",
    "    \"barndoor\": \"rural_or_recreational_area\",\n",
    "    \"beer_garden\": \"rural_or_recreational_area\",\n",
    "    \"beer_hall\": \"rural_or_recreational_area\",\n",
    "    \"botanical_garden\": \"rural_or_recreational_area\",\n",
    "    \"cabin_outdoor\": \"rural_or_recreational_area\",\n",
    "    \"campsite\": \"rural_or_recreational_area\",\n",
    "    \"campus\": \"rural_or_recreational_area\",\n",
    "    \"farm\": \"rural_or_recreational_area\",\n",
    "    \"field_cultivated\": \"rural_or_recreational_area\",\n",
    "    \"field_wild\": \"rural_or_recreational_area\",\n",
    "    \"golf_course\": \"rural_or_recreational_area\",\n",
    "    \"greenhouse_outdoor\": \"rural_or_recreational_area\",\n",
    "    \"hayfield\": \"rural_or_recreational_area\",\n",
    "    \"orchard\": \"rural_or_recreational_area\",\n",
    "    \"park\": \"rural_or_recreational_area\",\n",
    "    \"pasture\": \"rural_or_recreational_area\",\n",
    "    \"picnic_area\": \"rural_or_recreational_area\",\n",
    "    \"playground\": \"rural_or_recreational_area\",\n",
    "    \"rice_paddy\": \"rural_or_recreational_area\",\n",
    "    \"sandbox\": \"rural_or_recreational_area\",\n",
    "    \"stable\": \"rural_or_recreational_area\",\n",
    "    \"tree_farm\": \"rural_or_recreational_area\",\n",
    "    \"tree_house\": \"rural_or_recreational_area\",\n",
    "    \"village\": \"rural_or_recreational_area\",\n",
    "    \"vineyard\": \"rural_or_recreational_area\",\n",
    "    \"volleyball_court_outdoor\": \"rural_or_recreational_area\",\n",
    "    \"yard\": \"rural_or_recreational_area\",\n",
    "    \"corn_field\": \"rural_or_recreational_area\",\n",
    "    \"corral\": \"rural_or_recreational_area\",\n",
    "    \"cottage\": \"rural_or_recreational_area\",\n",
    "    \"formal_garden\": \"rural_or_recreational_area\",\n",
    "    \"greenhouse_indoor\": \"rural_or_recreational_area\",\n",
    "    \"hunting_lodge_outdoor\": \"rural_or_recreational_area\",\n",
    "    \"inn_outdoor\": \"rural_or_recreational_area\",\n",
    "    \"kennel_outdoor\": \"rural_or_recreational_area\",\n",
    "    \"pavilion\": \"rural_or_recreational_area\",\n",
    "    \"oast_house\": \"rural_or_recreational_area\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f00d30d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aquatic_environment',\n",
       " 'cold_environment',\n",
       " 'cultural_space',\n",
       " 'indoor_commercial',\n",
       " 'indoor_institutional',\n",
       " 'indoor_residential',\n",
       " 'industrial_facility',\n",
       " 'natural_landscape',\n",
       " 'religious_or_historical_site',\n",
       " 'rural_or_recreational_area',\n",
       " 'sports_and_entertainment',\n",
       " 'transport_infrastructure',\n",
       " 'urban_outdoor'}"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(places365_to_13categories.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5f1077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape:  (13135, 10)\n",
      "Test set shape:  (3284, 10)\n"
     ]
    }
   ],
   "source": [
    "# Now create train/test splits with clean data\n",
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "df_train, df_test = df_train.reset_index(drop=True), df_test.reset_index(drop=True)\n",
    "print(\"Training set shape: \",df_train.shape)\n",
    "print(\"Test set shape: \",df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca52981c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 1 files: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained models\n"
     ]
    }
   ],
   "source": [
    "face_processor = AutoImageProcessor.from_pretrained(\"trpakov/vit-face-expression\", use_fast=True)\n",
    "face_model = AutoModelForImageClassification.from_pretrained(\"trpakov/vit-face-expression\")\n",
    "\n",
    "face_detector = MTCNN()\n",
    "\n",
    "scene_processor = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load pretrained Places365 ResNet18\n",
    "scene_model = models.resnet18(num_classes=365)\n",
    "weights_url = \"http://places2.csail.mit.edu/models_places365/resnet18_places365.pth.tar\"\n",
    "checkpoint = torch.hub.load_state_dict_from_url(weights_url, map_location=\"cpu\")\n",
    "state_dict = {k.replace(\"module.\", \"\"): v for k, v in checkpoint[\"state_dict\"].items()}\n",
    "scene_model.load_state_dict(state_dict)\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# scene_model.to(device)\n",
    "\n",
    "# face_model.to(device)\n",
    "\n",
    "print(\"Loaded pretrained models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750ad434",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TruncatedFaceModel(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits_list = []\n",
    "        for face_tensor in x:\n",
    "            face_output = self.model(face_tensor)\n",
    "            face_logits = face_output.logits[:, :6]\n",
    "            logits_list.append(face_logits)\n",
    "\n",
    "        stacked = torch.cat(logits_list, dim=0)  # Stack along batch dimension\n",
    "        return stacked.flatten()\n",
    "    \n",
    "face_model_truncated = TruncatedFaceModel(face_model)\n",
    "face_network = Network(face_model_truncated, \"face_model\", batching = True)\n",
    "face_network.optimizer = torch.optim.Adam(face_network.parameters(), lr=lr_faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a73ef79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SceneReductionModel(nn.Module):\n",
    "    def __init__(self, input_dim=365, hidden_dim=128, output_dim=13):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "scene_model_reduction = SceneReductionModel()\n",
    "scene_reduction_network = Network(scene_model_reduction, \"scene_reduction\", batching = True)\n",
    "scene_reduction_network.optimizer= torch.optim.Adam(scene_reduction_network.parameters(), lr=lr_scene_reduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95af5ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TruncatedSceneModel(nn.Module):\n",
    "    def __init__(self, model, scene_reduction_model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.scene_reduction_model = scene_reduction_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        device = next(self.model.parameters()).device\n",
    "        x = x.to(device)\n",
    "        # x will be a tensor of the whole image (with the right preprocessing)\n",
    "        scene_output = self.model(x)\n",
    "        # Scene output has 365 values, we want it to be mapped to the 13 more common places\n",
    "        # That mapping happens through a neural network that will be trained during DPL training\n",
    "        scene_logits = self.scene_reduction_model(scene_output).squeeze(0)\n",
    "        return scene_logits\n",
    "    \n",
    "scene_model_truncated = TruncatedSceneModel(scene_model, scene_model_reduction)\n",
    "scene_network = Network(scene_model_truncated, \"scene_model\", batching = True)\n",
    "scene_network.optimizer = torch.optim.Adam(scene_network.parameters(), lr=lr_scenes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1cf56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FindingEmoFaces(object):\n",
    "    def __init__(self, df, subset, face_detector, max_size=2048):\n",
    "        self.df = df\n",
    "        self.face_detector = face_detector\n",
    "        self.max_size = max_size\n",
    "        self.subset = subset\n",
    "        self.save_path = os.path.join(findingemo_dir, \"precomputed\", \"detected_faces\", subset)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        index = int(item[0]) if isinstance(item, (tuple, list)) else int(item)\n",
    "        # Load the tensor\n",
    "        tensor = torch.load(os.path.join(self.save_path, f\"{index}.pt\"))\n",
    "        return tensor\n",
    "\n",
    "facetensors_train = FindingEmoFaces(df_train, \"train\", face_detector)\n",
    "facetensors_test = FindingEmoFaces(df_test, \"test\", face_detector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c66d43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FindingEmoScene(object):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        index = int(item[0]) if isinstance(item, (tuple, list)) else int(item)\n",
    "        img_path = os.path.join(findingemo_dir, self.df.iloc[index][\"image_path\"])\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        x = scene_processor(img).unsqueeze(0)\n",
    " \n",
    "        return x\n",
    "    \n",
    "scenetensors_train = FindingEmoScene(df_train)\n",
    "scenetensors_test = FindingEmoScene(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f11c5e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 224, 224])\n",
      "tensor([-0.3154,  0.0289, -0.2803,  0.2321, -0.1322,  0.1622,  0.2603, -0.2541,\n",
      "        -0.0596,  0.1122, -0.2275, -0.2385, -0.1646], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "torch.Size([13])\n"
     ]
    }
   ],
   "source": [
    "x = scenetensors_train[0]\n",
    "print(x.shape)\n",
    "y = scene_model_truncated(x)\n",
    "print(y)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739e8ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3, 224, 224])\n",
      "DEBUG: face_batch shape before model: torch.Size([1, 3, 3, 224, 224])\n",
      "\n",
      "DEBUG: face_batch shape before model: torch.Size([1, 3, 3, 224, 224])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [393], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m x \u001b[38;5;241m=\u001b[39m facetensors_train[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m----> 3\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mface_model_truncated\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(y)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(y\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\Users\\jarne\\miniconda3\\envs\\deepproblog\\lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jarne\\miniconda3\\envs\\deepproblog\\lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn [388], line 39\u001b[0m, in \u001b[0;36mTruncatedFaceModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDEBUG: face_batch shape before model:\u001b[39m\u001b[38;5;124m\"\u001b[39m, face_batch\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 39\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m     face_logits \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mlogits[:, :\u001b[38;5;241m6\u001b[39m]\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Ensure output is always 1D tensor\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jarne\\miniconda3\\envs\\deepproblog\\lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jarne\\miniconda3\\envs\\deepproblog\\lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\jarne\\miniconda3\\envs\\deepproblog\\lib\\site-packages\\transformers\\utils\\generic.py:940\u001b[0m, in \u001b[0;36mcan_return_tuple.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    938\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict_passed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    939\u001b[0m     return_dict \u001b[38;5;241m=\u001b[39m return_dict_passed\n\u001b[1;32m--> 940\u001b[0m output \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    941\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    942\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_tuple()\n",
      "File \u001b[1;32mc:\\Users\\jarne\\miniconda3\\envs\\deepproblog\\lib\\site-packages\\transformers\\models\\vit\\modeling_vit.py:669\u001b[0m, in \u001b[0;36mViTForImageClassification.forward\u001b[1;34m(self, pixel_values, head_mask, labels, interpolate_pos_encoding, **kwargs)\u001b[0m\n\u001b[0;32m    652\u001b[0m \u001b[38;5;129m@can_return_tuple\u001b[39m\n\u001b[0;32m    653\u001b[0m \u001b[38;5;129m@auto_docstring\u001b[39m\n\u001b[0;32m    654\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    660\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Unpack[TransformersKwargs],\n\u001b[0;32m    661\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ImageClassifierOutput:\n\u001b[0;32m    662\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    663\u001b[0m \u001b[38;5;124;03m    labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m    664\u001b[0m \u001b[38;5;124;03m        Labels for computing the image classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[0;32m    665\u001b[0m \u001b[38;5;124;03m        config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[0;32m    666\u001b[0m \u001b[38;5;124;03m        `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[0;32m    667\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 669\u001b[0m     outputs: BaseModelOutputWithPooling \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvit(\n\u001b[0;32m    670\u001b[0m         pixel_values,\n\u001b[0;32m    671\u001b[0m         head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[0;32m    672\u001b[0m         interpolate_pos_encoding\u001b[38;5;241m=\u001b[39minterpolate_pos_encoding,\n\u001b[0;32m    673\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    674\u001b[0m     )\n\u001b[0;32m    676\u001b[0m     sequence_output \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state\n\u001b[0;32m    677\u001b[0m     pooled_output \u001b[38;5;241m=\u001b[39m sequence_output[:, \u001b[38;5;241m0\u001b[39m, :]\n",
      "File \u001b[1;32mc:\\Users\\jarne\\miniconda3\\envs\\deepproblog\\lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jarne\\miniconda3\\envs\\deepproblog\\lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\jarne\\miniconda3\\envs\\deepproblog\\lib\\site-packages\\transformers\\utils\\generic.py:1064\u001b[0m, in \u001b[0;36mcheck_model_inputs.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1061\u001b[0m                 module\u001b[38;5;241m.\u001b[39mforward \u001b[38;5;241m=\u001b[39m make_capture_wrapper(module, original_forward, key, specs\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m   1062\u001b[0m                 monkey_patched_layers\u001b[38;5;241m.\u001b[39mappend((module, original_forward))\n\u001b[1;32m-> 1064\u001b[0m outputs \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1065\u001b[0m \u001b[38;5;66;03m# Restore original forward methods\u001b[39;00m\n\u001b[0;32m   1066\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module, original_forward \u001b[38;5;129;01min\u001b[39;00m monkey_patched_layers:\n",
      "File \u001b[1;32mc:\\Users\\jarne\\miniconda3\\envs\\deepproblog\\lib\\site-packages\\transformers\\models\\vit\\modeling_vit.py:482\u001b[0m, in \u001b[0;36mViTModel.forward\u001b[1;34m(self, pixel_values, bool_masked_pos, head_mask, interpolate_pos_encoding, **kwargs)\u001b[0m\n\u001b[0;32m    479\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pixel_values\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m expected_dtype:\n\u001b[0;32m    480\u001b[0m     pixel_values \u001b[38;5;241m=\u001b[39m pixel_values\u001b[38;5;241m.\u001b[39mto(expected_dtype)\n\u001b[1;32m--> 482\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpixel_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbool_masked_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbool_masked_pos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolate_pos_encoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolate_pos_encoding\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    486\u001b[0m encoder_outputs: BaseModelOutput \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(embedding_output, head_mask\u001b[38;5;241m=\u001b[39mhead_mask)\n\u001b[0;32m    488\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state\n",
      "File \u001b[1;32mc:\\Users\\jarne\\miniconda3\\envs\\deepproblog\\lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jarne\\miniconda3\\envs\\deepproblog\\lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\jarne\\miniconda3\\envs\\deepproblog\\lib\\site-packages\\transformers\\models\\vit\\modeling_vit.py:107\u001b[0m, in \u001b[0;36mViTEmbeddings.forward\u001b[1;34m(self, pixel_values, bool_masked_pos, interpolate_pos_encoding)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    103\u001b[0m     pixel_values: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m    104\u001b[0m     bool_masked_pos: Optional[torch\u001b[38;5;241m.\u001b[39mBoolTensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    105\u001b[0m     interpolate_pos_encoding: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    106\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m--> 107\u001b[0m     batch_size, num_channels, height, width \u001b[38;5;241m=\u001b[39m pixel_values\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    108\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_embeddings(pixel_values, interpolate_pos_encoding\u001b[38;5;241m=\u001b[39minterpolate_pos_encoding)\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bool_masked_pos \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 4)"
     ]
    }
   ],
   "source": [
    "x = facetensors_train[0]\n",
    "print(x.shape)\n",
    "y = face_model_truncated(x)\n",
    "print(y)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394fada7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(\n",
    "    os.path.join(prolog_dir, \"model3.pl\"),\n",
    "    [face_network, scene_reduction_network, scene_network]\n",
    ")\n",
    "engine = ExactEngine(model)\n",
    "model.set_engine(engine, cache=False)\n",
    "model.optimizer = SGD(model, param_lr=lr_model)\n",
    "\n",
    "model.add_tensor_source(\"train_face\", facetensors_train)\n",
    "model.add_tensor_source(\"train_scene\", scenetensors_train)\n",
    "model.add_tensor_source(\"test_face\", facetensors_test)\n",
    "model.add_tensor_source(\"test_scene\", scenetensors_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa9bb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FindingEmo(Dataset, TorchDataset):\n",
    "    def __init__(self, indices, df, subset_name):\n",
    "        super(FindingEmo, self).__init__()\n",
    "        self.df = df\n",
    "        self.subset_name = subset_name\n",
    "        self.data = indices\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def to_query(self, i):\n",
    "        sample_idx = self.data[i]\n",
    "        emotion_idx = self.df.iloc[sample_idx]['emotion_8_idx']\n",
    "\n",
    "        E = Var(\"E\")\n",
    "\n",
    "        goal = Term(\"final_emo\",\n",
    "                    Term(\"tensor\", Term(f\"{self.subset_name}_face\", Constant(sample_idx))),\n",
    "                    Term(\"tensor\", Term(f\"{self.subset_name}_scene\", Constant(sample_idx))),\n",
    "                    E)\n",
    "        \n",
    "        return Query(goal, substitution={E: Constant(emotion_idx)})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00cb458",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_size = int(len(df_train) * training_size_perc)\n",
    "\n",
    "train_indices = list(range(0, training_size))\n",
    "test_indices = list(range(0,len(df_test)))\n",
    "\n",
    "train_set = FindingEmo(train_indices, df_train, \"train\")\n",
    "test_set = FindingEmo(test_indices, df_test, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410ad2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loader= DataLoader(train_set,batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec16965f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from problog.logic import Term, Constant, list2term\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def softmax_to_list(tensor_term):\n",
    "    \"\"\"\n",
    "    Softmax function that returns a Prolog list of probabilities\n",
    "    Handles int (-1) error, device consistency, and tensor shape.\n",
    "    \"\"\"\n",
    "    # If tensor_term is a Term, use engine.get_tensor\n",
    "    if hasattr(tensor_term, \"functor\") and tensor_term.functor == \"tensor\":\n",
    "        tensor = engine.get_tensor(tensor_term)\n",
    "    # If tensor_term is an int, get directly from tensor_store\n",
    "    elif isinstance(tensor_term, int):\n",
    "        if tensor_term == -1:\n",
    "            print(\"ERROR: softmax_to_list received -1 (tensor not found)\")\n",
    "            return list2term([])\n",
    "        tensor = engine.tensor_store.get(tensor_term, None)\n",
    "        if tensor is None:\n",
    "            print(f\"ERROR: tensor_store has no entry for {tensor_term}\")\n",
    "            return list2term([])\n",
    "    else:\n",
    "        tensor = tensor_term  # fallback, may be a tensor already\n",
    "\n",
    "    if not isinstance(tensor, torch.Tensor):\n",
    "        print(f\"ERROR: softmax_to_list received non-tensor: {type(tensor)}\")\n",
    "        return list2term([])\n",
    "\n",
    "    # Move tensor to CPU for softmax if needed\n",
    "    if tensor.device.type != \"cpu\":\n",
    "        tensor = tensor.cpu()\n",
    "\n",
    "    # Flatten if needed\n",
    "    if tensor.ndim == 0:\n",
    "        tensor = tensor.unsqueeze(0)\n",
    "    elif tensor.ndim > 1:\n",
    "        tensor = tensor.view(-1)\n",
    "\n",
    "    # Apply softmax\n",
    "    probs = F.softmax(tensor, dim=-1)\n",
    "\n",
    "    # Convert to Python list of floats\n",
    "    prob_list = probs.tolist()\n",
    "\n",
    "    # Convert to Prolog list format\n",
    "    prolog_constants = [Constant(float(p)) for p in prob_list]\n",
    "    prolog_list = list2term(prolog_constants)\n",
    "\n",
    "    return prolog_list\n",
    "\n",
    "# Register the function with your engine\n",
    "engine.register_foreign(\n",
    "    func=softmax_to_list,\n",
    "    function_name=\"softmax\",\n",
    "    arity_in=1,   # Takes tensor input\n",
    "    arity_out=1   # Returns Prolog list\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d37ab8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_print(x):\n",
    "    print(\"DEBUG Facelogits value:\", x)\n",
    "    print(\"Type:\", type(x))\n",
    "    if hasattr(x, \"shape\"):\n",
    "        print(\"Shape:\", x.shape)\n",
    "    if isinstance(x, torch.Tensor):\n",
    "        print(\"Tensor device:\", x.device)\n",
    "        print(\"Tensor dtype:\", x.dtype)\n",
    "        print(\"Tensor min:\", x.min().item(), \"max:\", x.max().item())\n",
    "        # Check device consistency with model\n",
    "        try:\n",
    "            import gc\n",
    "            for obj in gc.get_objects():\n",
    "                if hasattr(obj, 'parameters'):\n",
    "                    try:\n",
    "                        model_device = next(obj.parameters()).device\n",
    "                        if x.device != model_device:\n",
    "                            print(f\"WARNING: Tensor device {x.device} does not match model device {model_device}\")\n",
    "                    except Exception:\n",
    "                        pass\n",
    "        except Exception as e:\n",
    "            print(\"Device consistency check failed:\", e)\n",
    "    elif isinstance(x, int):\n",
    "        print(\"WARNING: Value is int, likely an error (-1 means tensor not found)\")\n",
    "    else:\n",
    "        print(\"WARNING: Unexpected type for debug_print\")\n",
    "    return ()\n",
    "\n",
    "engine.register_foreign(\n",
    "    func=debug_print,\n",
    "    function_name=\"debug_print\",\n",
    "    arity_in=1,\n",
    "    arity_out=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0639d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "print(facetensors_train[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7125ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3, 224, 224])\n",
      "DEBUG: face_batch shape before model: torch.Size([3, 3, 224, 224])\n",
      "tensor([-0.2959, -2.5035,  0.5354, -0.8110,  4.0392, -1.5357, -1.0524, -2.2824,\n",
      "        -0.5259, -2.4327,  2.8070,  3.7185, -0.6956, -1.1049,  1.4585, -2.2307,\n",
      "        -0.8984,  4.0905], device='cuda:0')\n",
      "torch.Size([18])\n"
     ]
    }
   ],
   "source": [
    "x = facetensors_train[0]\n",
    "print(x.shape)\n",
    "y = face_model_truncated(x)\n",
    "print(y)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7cf7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "x = scenetensors_train[0]\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667f4337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available train_face keys: ['df', 'face_detector', 'max_size', 'subset', 'save_path']\n"
     ]
    }
   ],
   "source": [
    "print(\"Available train_face keys:\", list(model.tensor_sources[\"train_face\"].__dict__.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3586ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual tensor fetch shape: torch.Size([3, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "x = facetensors_train[0]\n",
    "print(\"Manual tensor fetch shape:\", x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da15a6e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG Facelogits value: anger\n",
      "Type: <class 'problog.logic.Term'>\n",
      "WARNING: Unexpected type for debug_print\n",
      "DEBUG Facelogits value: disgust\n",
      "Type: <class 'problog.logic.Term'>\n",
      "WARNING: Unexpected type for debug_print\n",
      "DEBUG Facelogits value: fear\n",
      "Type: <class 'problog.logic.Term'>\n",
      "WARNING: Unexpected type for debug_print\n",
      "DEBUG Facelogits value: joy\n",
      "Type: <class 'problog.logic.Term'>\n",
      "WARNING: Unexpected type for debug_print\n",
      "DEBUG Facelogits value: sadness\n",
      "Type: <class 'problog.logic.Term'>\n",
      "WARNING: Unexpected type for debug_print\n",
      "DEBUG Facelogits value: surprise\n",
      "Type: <class 'problog.logic.Term'>\n",
      "WARNING: Unexpected type for debug_print\n",
      "DEBUG: face_batch shape before model: torch.Size([3, 3, 224, 224])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "invalid index of a 0-dim tensor. Use `tensor.item()` in Python or `tensor.item<T>()` in C++ to convert a 0-dim tensor to a number",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [357], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m goal \u001b[38;5;241m=\u001b[39m Term(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mface_emotion_prob\u001b[39m\u001b[38;5;124m\"\u001b[39m, Term(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensor\u001b[39m\u001b[38;5;124m\"\u001b[39m, Term(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_face\u001b[39m\u001b[38;5;124m\"\u001b[39m, Constant(\u001b[38;5;241m0\u001b[39m))), Var(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mE\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m      6\u001b[0m query \u001b[38;5;241m=\u001b[39m Query(goal, substitution\u001b[38;5;241m=\u001b[39m{})\n\u001b[1;32m----> 7\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDPL result:\u001b[39m\u001b[38;5;124m\"\u001b[39m, results[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\jarne\\miniconda3\\envs\\deepproblog\\lib\\site-packages\\deepproblog\\model.py:117\u001b[0m, in \u001b[0;36mModel.solve\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msolve\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch: Sequence[Query]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Result]:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jarne\\miniconda3\\envs\\deepproblog\\lib\\site-packages\\deepproblog\\solver.py:88\u001b[0m, in \u001b[0;36mSolver.solve\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m     86\u001b[0m acs: List[ArithmeticCircuit] \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache\u001b[38;5;241m.\u001b[39mget(q) \u001b[38;5;28;01mfor\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m batch]\n\u001b[0;32m     87\u001b[0m \u001b[38;5;66;03m# Evaluate ACs. Evaluate networks if necessary\u001b[39;00m\n\u001b[1;32m---> 88\u001b[0m result \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     89\u001b[0m     ac\u001b[38;5;241m.\u001b[39mevaluate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, batch[i]\u001b[38;5;241m.\u001b[39msubstitution) \u001b[38;5;28;01mfor\u001b[39;00m i, ac \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(acs)\n\u001b[0;32m     90\u001b[0m ]\n\u001b[0;32m     91\u001b[0m semirings \u001b[38;5;241m=\u001b[39m [r\u001b[38;5;241m.\u001b[39msemiring \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m result]\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39mperform_count(batch, (acs, semirings))\n",
      "File \u001b[1;32mc:\\Users\\jarne\\miniconda3\\envs\\deepproblog\\lib\\site-packages\\deepproblog\\solver.py:89\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     86\u001b[0m acs: List[ArithmeticCircuit] \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache\u001b[38;5;241m.\u001b[39mget(q) \u001b[38;5;28;01mfor\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m batch]\n\u001b[0;32m     87\u001b[0m \u001b[38;5;66;03m# Evaluate ACs. Evaluate networks if necessary\u001b[39;00m\n\u001b[0;32m     88\u001b[0m result \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m---> 89\u001b[0m     \u001b[43mac\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubstitution\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i, ac \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(acs)\n\u001b[0;32m     90\u001b[0m ]\n\u001b[0;32m     91\u001b[0m semirings \u001b[38;5;241m=\u001b[39m [r\u001b[38;5;241m.\u001b[39msemiring \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m result]\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39mperform_count(batch, (acs, semirings))\n",
      "File \u001b[1;32mc:\\Users\\jarne\\miniconda3\\envs\\deepproblog\\lib\\site-packages\\deepproblog\\arithmetic_circuit.py:60\u001b[0m, in \u001b[0;36mArithmeticCircuit.evaluate\u001b[1;34m(self, model, substitution, re_evaluate)\u001b[0m\n\u001b[0;32m     58\u001b[0m semiring \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msemiring(model, substitution, values)\n\u001b[0;32m     59\u001b[0m start \u001b[38;5;241m=\u001b[39m time()\n\u001b[1;32m---> 60\u001b[0m evaluation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msdd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msemiring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msemiring\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m substitution \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m     evaluation \u001b[38;5;241m=\u001b[39m {k\u001b[38;5;241m.\u001b[39mapply_term(substitution): evaluation[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m evaluation}\n",
      "File \u001b[1;32mc:\\Users\\jarne\\miniconda3\\envs\\deepproblog\\lib\\site-packages\\problog\\evaluator.py:423\u001b[0m, in \u001b[0;36mEvaluatable.evaluate\u001b[1;34m(self, index, semiring, evidence, weights, **kwargs)\u001b[0m\n\u001b[0;32m    411\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate\u001b[39m(\n\u001b[0;32m    412\u001b[0m     \u001b[38;5;28mself\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, semiring\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, evidence\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    413\u001b[0m ):\n\u001b[0;32m    414\u001b[0m     \u001b[38;5;124;03m\"\"\"Evaluate a set of nodes.\u001b[39;00m\n\u001b[0;32m    415\u001b[0m \n\u001b[0;32m    416\u001b[0m \u001b[38;5;124;03m    :param index: node to evaluate (default: all queries)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[38;5;124;03m     If index is ``None`` (all queries) then the result is a dictionary of name to value.\u001b[39;00m\n\u001b[0;32m    422\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 423\u001b[0m     evaluator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_evaluator(semiring, evidence, weights, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    425\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    426\u001b[0m         result \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32mc:\\Users\\jarne\\miniconda3\\envs\\deepproblog\\lib\\site-packages\\problog\\evaluator.py:408\u001b[0m, in \u001b[0;36mEvaluatable.get_evaluator\u001b[1;34m(self, semiring, evidence, weights, keep_evidence, **kwargs)\u001b[0m\n\u001b[0;32m    405\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m keep_evidence:\n\u001b[0;32m    406\u001b[0m                 evaluator\u001b[38;5;241m.\u001b[39madd_evidence(ev_value \u001b[38;5;241m*\u001b[39m ev_index)\n\u001b[1;32m--> 408\u001b[0m \u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m evaluator\n",
      "File \u001b[1;32mc:\\Users\\jarne\\miniconda3\\envs\\deepproblog\\lib\\site-packages\\problog\\dd_formula.py:445\u001b[0m, in \u001b[0;36mDDEvaluator.propagate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpropagate\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 445\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;66;03m# if (\u001b[39;00m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;66;03m#     type(self.semiring) == SemiringLogProbability\u001b[39;00m\n\u001b[0;32m    448\u001b[0m     \u001b[38;5;66;03m#     or type(self.semiring) == SemiringProbability\u001b[39;00m\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;66;03m# ):\u001b[39;00m\n\u001b[0;32m    450\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    451\u001b[0m             \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msemiring, SemiringLogProbability)\n\u001b[0;32m    452\u001b[0m             \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msemiring, SemiringProbability)\n\u001b[0;32m    453\u001b[0m     ):\n",
      "File \u001b[1;32mc:\\Users\\jarne\\miniconda3\\envs\\deepproblog\\lib\\site-packages\\problog\\dd_formula.py:430\u001b[0m, in \u001b[0;36mDDEvaluator._initialize\u001b[1;34m(self, with_evidence)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_initialize\u001b[39m(\u001b[38;5;28mself\u001b[39m, with_evidence\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    428\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m--> 430\u001b[0m     weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformula\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msemiring\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgiven_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    431\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m atom, weight \u001b[38;5;129;01min\u001b[39;00m weights\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    432\u001b[0m         av \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformula\u001b[38;5;241m.\u001b[39matom2var\u001b[38;5;241m.\u001b[39mget(atom)\n",
      "File \u001b[1;32mc:\\Users\\jarne\\miniconda3\\envs\\deepproblog\\lib\\site-packages\\problog\\formula.py:189\u001b[0m, in \u001b[0;36mBaseFormula.extract_weights\u001b[1;34m(self, semiring, weights)\u001b[0m\n\u001b[0;32m    186\u001b[0m             result[key] \u001b[38;5;241m=\u001b[39m semiring\u001b[38;5;241m.\u001b[39mtrue(name)\n\u001b[0;32m    187\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    188\u001b[0m             result[key] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 189\u001b[0m                 \u001b[43msemiring\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    190\u001b[0m                 semiring\u001b[38;5;241m.\u001b[39mneg_value(w, name),\n\u001b[0;32m    191\u001b[0m             )\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconstraints():\n\u001b[0;32m    194\u001b[0m     c\u001b[38;5;241m.\u001b[39mupdate_weights(result, semiring)\n",
      "File \u001b[1;32mc:\\Users\\jarne\\miniconda3\\envs\\deepproblog\\lib\\site-packages\\problog\\evaluator.py:107\u001b[0m, in \u001b[0;36mSemiring.pos_value\u001b[1;34m(self, a, key)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpos_value\u001b[39m(\u001b[38;5;28mself\u001b[39m, a, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;124;03m\"\"\"Extract the positive internal value for the given external value.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jarne\\miniconda3\\envs\\deepproblog\\lib\\site-packages\\deepproblog\\semiring\\graph_semiring.py:58\u001b[0m, in \u001b[0;36mGraphSemiring.value\u001b[1;34m(self, a, key)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(a\u001b[38;5;241m.\u001b[39margs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m     57\u001b[0m         i \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(a\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m---> 58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mval\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m a\u001b[38;5;241m.\u001b[39mfunctor \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     60\u001b[0m     i \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(a\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[1;31mIndexError\u001b[0m: invalid index of a 0-dim tensor. Use `tensor.item()` in Python or `tensor.item<T>()` in C++ to convert a 0-dim tensor to a number"
     ]
    }
   ],
   "source": [
    "# Python\n",
    "from problog.logic import Term, Constant, Var\n",
    "from deepproblog.query import Query\n",
    "\n",
    "goal = Term(\"face_emotion_prob\", Term(\"tensor\", Term(\"train_face\", Constant(0))), Var(\"E\"))\n",
    "query = Query(goal, substitution={})\n",
    "results = model.solve([query])\n",
    "print(\"DPL result:\", results[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepproblog",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
