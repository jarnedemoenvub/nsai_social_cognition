{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d9a443c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
    "import torch\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f975f83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 1 files: 100%|██████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load pretrained model + processor\n",
    "processor = AutoImageProcessor.from_pretrained(\"trpakov/vit-face-expression\")\n",
    "face_model = AutoModelForImageClassification.from_pretrained(\"trpakov/vit-face-expression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1d0656d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the database\n",
    "PATH = \"./data/fer2013/test/\"\n",
    "limit = 100\n",
    "emotions = [e for e in os.listdir(PATH)]\n",
    "rows=[]\n",
    "\n",
    "for emotion in emotions:\n",
    "    current_path = PATH + emotion\n",
    "    for (i,file) in enumerate(os.listdir(current_path)):\n",
    "        file_path = current_path + \"/\" + file\n",
    "        img = cv2.imread(file_path)\n",
    "        if i == limit:\n",
    "            break\n",
    "        rows.append({\"image\":img, \"emotion\":emotion})\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "# Shuffle the dataframe\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5432411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 48, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"image\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912966df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Emotion: fear\n",
      "Predictions:\n",
      "  angry: 0.79%\n",
      "  disgust: 1.06%\n",
      "  fear: 92.62%\n",
      "  happy: 0.79%\n",
      "  neutral: 1.32%\n",
      "  sad: 2.56%\n",
      "  surprise: 0.86%\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQgJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAwADADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDyzSYBITx8oPX1NdhY26Ow449K5/SYCjbQMBFGfqRk1tw3zwNiFASB8zN0/SgDoRp6CIMFzmoprNCgyvUVSstfuJXxK8WxTyAjDH1NWtW1SKCBVS4t1Oz77OMCgDi/EtssWH28Z5xVzwJeMGu7CViIlxMDn14P58VQ1iea8tZP9JjuFA6xxMMfiRWh4PjVraa5Ur5mFQgoG6ZPfpQBDo9hHevJJNvOTjiQgfpVuXSI7BpjHHN5ExVs5LAEdQe+Kl0SPyrYHn5mJNdLAAxUN0zQBzemwrbBvs+99uSEQEknHc/4mop9Ht7e0tZ0t0eaMnzWVBl9wOT79a6/UXR8QQDCgfN7+1Z10LmO0KhU2HnAHI+lAHKfZYoWZU3tlSANjZAznHStLwhZCCC6cAgSycL6ACtG9dDYiRSfudadpMJt7S1GPvoWP1zn+tAGZo9+LqNmdFjZicoD0roLfkAZIyKoa1YmFhdW8WDn96FHfsaTTtQWWLaxAdeDmgC1dvPHOVhUkA8sOT+VRahOz2+IYrgNjG6RxgH1xVwTws20sAx561HemJV++G7nNAGZJCWtYItxLSnH055rRiI+z2xPG1ihNZsTtLIswB2xnK+/PNaKuvkuM/dm3DnqKAP/2Q==",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=48x48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "import torch\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "def show_image_and_prediction(index):\n",
    "    image = df[\"image\"][index]\n",
    "    emotion = df[\"emotion\"][index]\n",
    "\n",
    "    # Convert to PIL (OpenCV loads BGR)\n",
    "    image_pil = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    # Preprocess\n",
    "    inputs = processor(images=image_pil, return_tensors=\"pt\")\n",
    "\n",
    "    # Inference\n",
    "    with torch.no_grad():\n",
    "        logits = face_model(**inputs).logits\n",
    "        probs = torch.nn.functional.softmax(logits, dim=-1)[0]\n",
    "\n",
    "    # Print true label\n",
    "    print(f\"True Emotion: {emotion}\")\n",
    "    print(\"Predictions:\")\n",
    "\n",
    "    # Print each class with % probability\n",
    "    for i, p in enumerate(probs):\n",
    "        label = face_model.config.id2label[i]\n",
    "        print(f\"  {label}: {p.item()*100:.2f}%\")\n",
    "\n",
    "    # Display image\n",
    "    display(image_pil)\n",
    "\n",
    "# Example\n",
    "show_image_and_prediction(random.randint(0, len(df)-1))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepproblog",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
